{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78805358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.signal import savgol_filter\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from transformers import pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from data.dataset_factory import get_dataset_generator\n",
    "from data.data_generators.sourcecodeplag_dataset_gen import original_plag_triplet_generator\n",
    "from preprocessing.embedding_chunks import get_ready_to_embed_chunks\n",
    "from preprocessing.context_chunker import safe_get_ready_to_embed_context_chunks\n",
    "from preprocessing.mean_pool_chunks import mean_pool_chunks\n",
    "from preprocessing.block_splitter import deverbose_ast\n",
    "from visualizer.smoothing import smooth_embeddings, smooth_multiple_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d118c5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = get_dataset_generator(\n",
    "    dataset_name='sourcecodeplag',\n",
    "    mode='plagiarized',\n",
    "    **{}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f383a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unixcoder = \"microsoft/unixcoder-base\"\n",
    "unixoder_pipe = pipeline(\"feature-extraction\", model=unixcoder)\n",
    "\n",
    "codebert = \"microsoft/codebert-base\"\n",
    "codebert_pipe = pipeline(\"feature-extraction\", model=codebert)\n",
    "\n",
    "graphcodebert = \"microsoft/graphcodebert-base\"\n",
    "graphcodebert_pipe = pipeline(\"feature-extraction\", model=graphcodebert)\n",
    "\n",
    "models = {\n",
    "    \"UniXcoder\": unixoder_pipe,\n",
    "    \"CodeBERT\": codebert_pipe,\n",
    "    \"GraphCodeBERT\": graphcodebert_pipe\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eb8248",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Embeddings:\n",
    "    \"\"\"\n",
    "    Represents a single fully embedded chunk\n",
    "    \"\"\"\n",
    "    code: str\n",
    "    ast: str\n",
    "    combined: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca20a4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(chunks, model, combine_strategy: callable):\n",
    "    \"\"\"\n",
    "    returns all chunks as embeddings\n",
    "    \"\"\"\n",
    "    embeddings_list: [Embeddings] = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        # 1 = code, 2 = ast\n",
    "        code = pipe(chunk[1])\n",
    "        ast = pipe(chunk[2])\n",
    "        embeddings_list.append(Embeddings(code=code, ast=ast, combined=combine_strategy(code, ast)))\n",
    "    \n",
    "    return embeddings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54d63ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pool(vec1, vec2):\n",
    "    v1 = np.array(vec1, dtype=float)\n",
    "    v2 = np.array(vec2, dtype=float)\n",
    "\n",
    "    if v1.shape != v2.shape:\n",
    "        raise ValueError(\"Vectors must have the same length\")\n",
    "\n",
    "    pooled = (v1 + v2) / 2.0\n",
    "    return pooled.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b412bf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sample(sample):\n",
    "    \"\"\"\n",
    "    Takes single sample and processes it using multiple chunking strategies and a way for different poooling straegies\n",
    "    \"\"\"\n",
    "    code_a = sample.code_a\n",
    "    line_chunks_a = get_ready_to_embed_chunks(code_a)\n",
    "    context_chunks_a = safe_get_ready_to_embed_context_chunks(code_a)\n",
    "\n",
    "    code_b = sample.code_b\n",
    "    line_chunks_b = get_ready_to_embed_chunks(code_b)\n",
    "    context_chunks_b = safe_get_ready_to_embed_context_chunks(code_b)\n",
    "\n",
    "    # Mean pooling strategy\n",
    "    for model in models:\n",
    "        line_embeddings_a = embed(line_chunks_a, model, mean_pool)\n",
    "        contenxt_embeddings_a = embed(context_chunks_a, model, mean_pool)\n",
    "\n",
    "        line_embeddings_b = embed(line_chunks_b, model, mean_pool)\n",
    "        contenxt_embeddings_b = embed(context_chunks_b, model, mean_pool)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97148d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in gen:\n",
    "    process_sample()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
