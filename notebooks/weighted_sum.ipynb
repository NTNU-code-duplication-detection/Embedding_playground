{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a15f139a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonas/Documents/NTNU/Bachelor/code-model-embeddings/venv/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.signal import savgol_filter\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "\n",
    "from transformers import pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "import javalang\n",
    "import tree_sitter_java\n",
    "from tree_sitter import Language, Parser\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from data.dataset_factory import get_dataset_generator\n",
    "from data.data_generators.sourcecodeplag_dataset_gen import original_plag_triplet_generator\n",
    "from preprocessing.embedding_chunks import get_ready_to_embed_chunks\n",
    "from preprocessing.context_chunker import safe_get_ready_to_embed_context_chunks\n",
    "from preprocessing.mean_pool_chunks import mean_pool_chunks\n",
    "from preprocessing.block_splitter import deverbose_ast\n",
    "from visualizer.smoothing import smooth_embeddings, smooth_multiple_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da5d41fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = \"\"\"\n",
    "public class T5 {\n",
    "\tpublic static void main(String[] args) {\n",
    "\t\tSystem.out.print(\"Enter an integer: \");\n",
    "\t\tjava.util.Scanner input = new java.util.Scanner(System.in);\n",
    "\t\tint number = input.nextInt();\n",
    "\t\treverse(number);\n",
    "\t}\n",
    "\n",
    "\tpublic static void reverse(int number) {\n",
    "\t\twhile (number != 0) {\n",
    "\t\t\tint remainder = number % 10;\n",
    "\t\t\tSystem.out.print(remainder);\n",
    "\t\t\tnumber = number / 10;\n",
    "\t\t}\n",
    "\n",
    "\t\tSystem.out.println();\n",
    "\t}\n",
    "\n",
    "}\n",
    "\"\"\"\n",
    "clone = \"\"\"import java.util.*;\n",
    "\n",
    "class method{\n",
    "\t//prog utama\n",
    "\tpublic static void main(String[] args) \n",
    "\t{\n",
    "\t\t\tSystem.out.print(\"Enter an integer: \");\n",
    "\t\t\tjava.util.Scanner input = new java.util.Scanner(System.in);\n",
    "\t\tint n = input.nextInt();\n",
    "\t\t//pamggil method\n",
    "\t\t\tbeautyReverse(n);\n",
    "\t}\n",
    "\t\n",
    "\t//method reverse\n",
    "\tpublic static void beautyReverse(int num) \n",
    "\t{\n",
    "\t\twhile (num != 0)\n",
    "\t\t\t{\n",
    "\t\t\tint r = num % 10;\n",
    "\t\t\t\tSystem.out.print(r);\n",
    "\t\t\tnum = num / 10;\n",
    "\t\t}\n",
    "\t\tSystem.out.println();\n",
    "\t}\n",
    "}\"\"\"\n",
    "non_clone = \"\"\"import java.util.Scanner;\n",
    "\n",
    "public class Main {\n",
    "    //function for Summary\n",
    "    public static double sumMajorDiagonal(double[][] mtx) {\n",
    "        double sum = 0;\n",
    "\n",
    "        for (int i = 0; i < mtx.length; i++)\n",
    "            sum += mtx[i][i];\n",
    "        return sum;\n",
    "    }\n",
    "\n",
    "    public static void main(String[] args) {\n",
    "\n",
    "        double[][] mtx = new double[4][4];\n",
    "        Scanner s = new Scanner(System.in);\n",
    "        //input 4*4 matrix data\n",
    "        System.out.print(\"Enter a 4 by 4 matrix row by row: \");\n",
    "\n",
    "\n",
    "        for (int i = 0; i < 4; i++)\n",
    "            for (int j = 0; j < 4; j++)\n",
    "                mtx[i][j] = s.nextDouble();\n",
    "\n",
    "\n",
    "        System.out.print(\"Sum of the elements in the major diagonal is \"+ sumMajorDiagonal(mtx));\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed83937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tree_sitter_java\n",
    "from tree_sitter import Language, Parser\n",
    "\n",
    "JAVA_LANGUAGE = Language(tree_sitter_java.language())\n",
    "parser = Parser(JAVA_LANGUAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f197b894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 197/197 [00:00<00:00, 2180.75it/s, Materializing param=encoder.layer.11.output.dense.weight]              \n",
      "RobertaModel LOAD REPORT from: microsoft/graphcodebert-base\n",
      "Key                             | Status     | \n",
      "--------------------------------+------------+-\n",
      "lm_head.layer_norm.weight       | UNEXPECTED | \n",
      "roberta.embeddings.position_ids | UNEXPECTED | \n",
      "lm_head.decoder.bias            | UNEXPECTED | \n",
      "lm_head.dense.bias              | UNEXPECTED | \n",
      "lm_head.decoder.weight          | UNEXPECTED | \n",
      "lm_head.dense.weight            | UNEXPECTED | \n",
      "lm_head.layer_norm.bias         | UNEXPECTED | \n",
      "lm_head.bias                    | UNEXPECTED | \n",
      "pooler.dense.bias               | MISSING    | \n",
      "pooler.dense.weight             | MISSING    | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"microsoft/graphcodebert-base\"\n",
    "pipe = pipeline(\"feature-extraction\", model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ada46c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunkKind(Enum):\n",
    "    STRAIGHT = \"straight\"\n",
    "    CONTROL = \"control\"\n",
    "\n",
    "@dataclass\n",
    "class Chunk:\n",
    "    text: str\n",
    "    embedding: None\n",
    "    ast_depth: int\n",
    "    kind: ChunkKind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df3ec649",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTROL_NODES = (\n",
    "    \"if_statement\",\n",
    "    \"for_statement\",\n",
    "    \"while_statement\",\n",
    "    \"do_statement\",\n",
    "    \"switch_statement\",\n",
    "    \"try_statement\",\n",
    "    \"catch_clause\",\n",
    ")\n",
    "\n",
    "STRAIGHT_NODES = (\n",
    "    \"local_variable_declaration\",\n",
    "    \"expression_statement\",\n",
    "    \"return_statement\",\n",
    "    \"throw_statement\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cbaac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_source_by_position(source_lines, node):\n",
    "    if not node.position:\n",
    "        return None\n",
    "\n",
    "    start_line = node.position.line - 1\n",
    "\n",
    "    # Heuristic: extract until block end\n",
    "    # (works well for control-flow)\n",
    "    lines = source_lines[start_line:start_line + 20]\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc53ab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JavaChunkExtractor:\n",
    "    def __init__(self, source_code):\n",
    "        self.source = source_code\n",
    "        self.lines = source_code.splitlines()\n",
    "        self.chunks = []\n",
    "\n",
    "    def visit(self, node, depth=0):\n",
    "        if isinstance(node, CONTROL_NODES):\n",
    "            self._add_chunk(node, depth, ChunkKind.CONTROL)\n",
    "\n",
    "        elif isinstance(node, STRAIGHT_NODES):\n",
    "            self._add_chunk(node, depth, ChunkKind.STRAIGHT)\n",
    "\n",
    "        for _, child in node.filter(javalang.tree.Node):\n",
    "            self.visit(child, depth + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3c15967",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeSitterJavaChunker:\n",
    "    def __init__(self, source_code: str):\n",
    "        self.code = source_code.encode(\"utf8\")\n",
    "        self.chunks = []\n",
    "\n",
    "    def extract(self):\n",
    "        tree = parser.parse(self.code)\n",
    "        self._visit(tree.root_node, depth=0)\n",
    "        return self.chunks\n",
    "\n",
    "    def _visit(self, node, depth):\n",
    "        # Only consider nodes that correspond to statements\n",
    "        if node.type in CONTROL_NODES:\n",
    "            self._add_chunk(node, depth, ChunkKind.CONTROL)\n",
    "        elif node.type in STRAIGHT_NODES:\n",
    "            self._add_chunk(node, depth, ChunkKind.STRAIGHT)\n",
    "\n",
    "        # Recurse to children\n",
    "        for child in node.children:\n",
    "            # skip tokens\n",
    "            if len(child.children) == 0 and child.type in (';', '{', '}', '(', ')', ','):\n",
    "                continue\n",
    "            self._visit(child, depth + 1)\n",
    "\n",
    "\n",
    "    def _add_chunk(self, node, depth, kind):\n",
    "        text = self.code[node.start_byte : node.end_byte].decode(\"utf8\")\n",
    "\n",
    "        self.chunks.append(\n",
    "            Chunk(\n",
    "                text=text,\n",
    "                embedding=None,\n",
    "                ast_depth=depth,\n",
    "                kind=kind,\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ba172ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_and_chunk_java(code: str):\n",
    "    chunker = TreeSitterJavaChunker(code)\n",
    "    chunks = chunker.extract()\n",
    "\n",
    "    S_chunks = [c for c in chunks if c.kind == ChunkKind.STRAIGHT]\n",
    "    C_chunks = [c for c in chunks if c.kind == ChunkKind.CONTROL]\n",
    "\n",
    "    return S_chunks, C_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c1a9495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_chunk_text(text):\n",
    "    \"\"\"Embed a single code chunk as a fixed vector\"\"\"\n",
    "    outputs = pipe(text)            # shape: [1, seq_len, hidden_dim]\n",
    "    arr = np.array(outputs[0])      # shape: [seq_len, hidden_dim]\n",
    "    return arr.mean(axis=0)         # mean over tokens → shape: (hidden_dim,)\n",
    "\n",
    "\n",
    "def embed_chunks(S, C):\n",
    "    for chunk in S + C:\n",
    "        text = chunk.text.strip()\n",
    "        if text == \"\":\n",
    "            continue\n",
    "        chunk.embedding = embed_chunk_text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22ee3096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def combine_chunks(chunks):\n",
    "    if len(chunks) == 0:\n",
    "        return np.zeros(768)  # same embedding size as GraphCodeBERT\n",
    "    vectors = []\n",
    "    weights = []\n",
    "    for chunk in chunks:\n",
    "        vectors.append(chunk.embedding)\n",
    "        # Weight = 1 for STRAIGHT, 2 for CONTROL, optionally multiply by depth\n",
    "        w = 1 if chunk.kind.name == \"STRAIGHT\" else 2\n",
    "        w *= (chunk.ast_depth + 1)\n",
    "        weights.append(w)\n",
    "    vectors = np.array(vectors)\n",
    "    weights = np.array(weights).reshape(-1, 1)\n",
    "    weighted_sum = np.sum(vectors * weights, axis=0)\n",
    "    summary = weighted_sum / weights.sum()\n",
    "    return summary  # single vector representing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "480f83bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_chunks(S, C):\n",
    "    print(\"STRAIGHT CHUNKS:\")\n",
    "    for chunk in S:\n",
    "        print(f\"- {chunk.text}\")\n",
    "\n",
    "    print(\"\\nCONTROL CHUNKS:\")\n",
    "    for chunk in C:\n",
    "        print(f\"- {chunk.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c58da13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STRAIGHT CHUNKS:\n",
      "- System.out.print(\"Enter an integer: \");\n",
      "- java.util.Scanner input = new java.util.Scanner(System.in);\n",
      "- int number = input.nextInt();\n",
      "- reverse(number);\n",
      "- int remainder = number % 10;\n",
      "- System.out.print(remainder);\n",
      "- number = number / 10;\n",
      "- System.out.println();\n",
      "\n",
      "CONTROL CHUNKS:\n",
      "- while (number != 0) {\n",
      "\t\t\tint remainder = number % 10;\n",
      "\t\t\tSystem.out.print(remainder);\n",
      "\t\t\tnumber = number / 10;\n",
      "\t\t}\n",
      "STRAIGHT CHUNKS:\n",
      "- System.out.print(\"Enter an integer: \");\n",
      "- java.util.Scanner input = new java.util.Scanner(System.in);\n",
      "- int n = input.nextInt();\n",
      "- beautyReverse(n);\n",
      "- int r = num % 10;\n",
      "- System.out.print(r);\n",
      "- num = num / 10;\n",
      "- System.out.println();\n",
      "\n",
      "CONTROL CHUNKS:\n",
      "- while (num != 0)\n",
      "\t\t\t{\n",
      "\t\t\tint r = num % 10;\n",
      "\t\t\t\tSystem.out.print(r);\n",
      "\t\t\tnum = num / 10;\n",
      "\t\t}\n",
      "STRAIGHT CHUNKS:\n",
      "- double sum = 0;\n",
      "- int i = 0;\n",
      "- sum += mtx[i][i];\n",
      "- return sum;\n",
      "- double[][] mtx = new double[4][4];\n",
      "- Scanner s = new Scanner(System.in);\n",
      "- System.out.print(\"Enter a 4 by 4 matrix row by row: \");\n",
      "- int i = 0;\n",
      "- int j = 0;\n",
      "- mtx[i][j] = s.nextDouble();\n",
      "- System.out.print(\"Sum of the elements in the major diagonal is \"+ sumMajorDiagonal(mtx));\n",
      "\n",
      "CONTROL CHUNKS:\n",
      "- for (int i = 0; i < mtx.length; i++)\n",
      "            sum += mtx[i][i];\n",
      "- for (int i = 0; i < 4; i++)\n",
      "            for (int j = 0; j < 4; j++)\n",
      "                mtx[i][j] = s.nextDouble();\n",
      "- for (int j = 0; j < 4; j++)\n",
      "                mtx[i][j] = s.nextDouble();\n"
     ]
    }
   ],
   "source": [
    "S_anchor, C_anchor = parse_and_chunk_java(anchor)\n",
    "print_chunks(S_anchor, C_anchor)\n",
    "embed_chunks(S_anchor, C_anchor)\n",
    "#anchor_summary = combine_chunks(S_anchor + C_anchor)\n",
    "anchor_summary = 0.3 * combine_chunks(S_anchor) + 0.7 * combine_chunks(C_anchor)\n",
    "\n",
    "S_clone, C_clone = parse_and_chunk_java(clone)\n",
    "print_chunks(S_clone, C_clone)\n",
    "embed_chunks(S_clone, C_clone)\n",
    "#clone_summary = combine_chunks(S_clone + C_clone)\n",
    "clone_summary = 0.3 * combine_chunks(S_clone) + 0.7 * combine_chunks(C_clone)\n",
    "\n",
    "S_non, C_non = parse_and_chunk_java(non_clone)\n",
    "print_chunks(S_non, C_non)\n",
    "embed_chunks(S_non, C_non)\n",
    "#non_clone_summary = combine_chunks(S_non + C_non)\n",
    "non_clone_summary = 0.3 * combine_chunks(S_non) + 0.7 * combine_chunks(C_non)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a95721b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1389012820380315\n",
      "0.9789242655999484\n",
      "0.8595338943329472\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (norm(a) * norm(b))\n",
    "\n",
    "\n",
    "sim_clone = cosine_similarity(anchor_summary, clone_summary)\n",
    "sim_non_clone = cosine_similarity(anchor_summary, non_clone_summary)\n",
    "\n",
    "score = sim_clone / (sim_non_clone + 1e-8)  # higher is better\n",
    "\n",
    "print(score)\n",
    "print(sim_clone)\n",
    "print(sim_non_clone)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0afcf734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"Compute cosine similarity between two vectors.\"\"\"\n",
    "    a_norm = norm(a)\n",
    "    b_norm = norm(b)\n",
    "    if a_norm == 0 or b_norm == 0:\n",
    "        return 0.0\n",
    "    return np.dot(a, b) / (a_norm * b_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c56fe5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal weights: STRAIGHT=0.90, CONTROL=0.10, avg_score=1.063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm  # optional, for progress bar\n",
    "\n",
    "best_score = -1\n",
    "best_wS = 0.3\n",
    "\n",
    "# Use the generator\n",
    "triplets = list(original_plag_triplet_generator(seed=42))\n",
    "\n",
    "for wS in np.arange(0.1, 0.9 + 1e-5, 0.05):\n",
    "    wC = 1.0 - wS\n",
    "    total_score = 0\n",
    "\n",
    "    for triplet in tqdm(triplets, desc=f\"wS={wS:.2f}\", leave=False):\n",
    "        anchor = triplet[\"anchor\"]\n",
    "        clone = triplet[\"clone\"]\n",
    "        non_clone = triplet[\"nonclone\"]\n",
    "\n",
    "        # 1️⃣ Parse chunks\n",
    "        S_a, C_a = parse_and_chunk_java(anchor)\n",
    "        S_c, C_c = parse_and_chunk_java(clone)\n",
    "        S_nc, C_nc = parse_and_chunk_java(non_clone)\n",
    "\n",
    "        # 2️⃣ Embed\n",
    "        embed_chunks(S_a, C_a)\n",
    "        embed_chunks(S_c, C_c)\n",
    "        embed_chunks(S_nc, C_nc)\n",
    "\n",
    "        # 3️⃣ Weighted summary vector\n",
    "        summary_anchor = wS * combine_chunks(S_a) + wC * combine_chunks(C_a)\n",
    "        summary_clone  = wS * combine_chunks(S_c) + wC * combine_chunks(C_c)\n",
    "        summary_non    = wS * combine_chunks(S_nc) + wC * combine_chunks(C_nc)\n",
    "\n",
    "        # 4️⃣ Cosine similarity ratio\n",
    "        sim_clone     = cosine_similarity(summary_anchor, summary_clone)\n",
    "        sim_non_clone = cosine_similarity(summary_anchor, summary_non)\n",
    "        total_score += sim_clone / (sim_non_clone + 1e-8)\n",
    "\n",
    "    avg_score = total_score / len(triplets)\n",
    "    if avg_score > best_score:\n",
    "        best_score = avg_score\n",
    "        best_wS = wS    \n",
    "\n",
    "print(f\"Optimal weights: STRAIGHT={best_wS:.2f}, CONTROL={1-best_wS:.2f}, avg_score={best_score:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
